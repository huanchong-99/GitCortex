{"version":3,"file":"lite-batcher.cjs","sources":["../../src/lite-batcher.ts"],"sourcesContent":["/**\n * Options for configuring a lite batcher instance\n */\nexport interface LiteBatcherOptions<TValue> {\n  /**\n   * Custom function to determine if a batch should be processed\n   * Return true to process the batch immediately\n   */\n  getShouldExecute?: (\n    items: Array<TValue>,\n    batcher: LiteBatcher<TValue>,\n  ) => boolean\n  /**\n   * Maximum number of items in a batch\n   * @default Infinity\n   */\n  maxSize?: number\n  /**\n   * Callback fired after a batch is processed\n   */\n  onExecute?: (batch: Array<TValue>, batcher: LiteBatcher<TValue>) => void\n  /**\n   * Callback fired after items are added to the batcher\n   */\n  onItemsChange?: (batcher: LiteBatcher<TValue>) => void\n  /**\n   * Whether the batcher should start processing immediately\n   * @default true\n   */\n  started?: boolean\n  /**\n   * Maximum time in milliseconds to wait before processing a batch.\n   * If the wait duration has elapsed, the batch will be processed.\n   * If not provided, the batch will not be triggered by a timeout.\n   * @default Infinity\n   */\n  wait?: number | ((batcher: LiteBatcher<TValue>) => number)\n}\n\n/**\n * A lightweight class that collects items and processes them in batches.\n *\n * This is an alternative to the Batcher in the core @tanstack/pacer package, but is more\n * suitable for libraries and npm packages that need minimal overhead. Unlike the core Batcher,\n * this version does not use TanStack Store for state management, has no devtools integration,\n * no callbacks, and provides only essential batching functionality.\n *\n * Batching is a technique for grouping multiple operations together to be processed as a single unit.\n * This synchronous version is lighter weight and often all you need.\n *\n * The Batcher provides a flexible way to implement batching with configurable:\n * - Maximum batch size (number of items per batch)\n * - Time-based batching (process after X milliseconds)\n * - Custom batch processing logic via getShouldExecute\n *\n * Features included:\n * - Core batching functionality (addItem, flush, clear, cancel)\n * - Size-based batching (maxSize)\n * - Time-based batching (wait timeout)\n * - Custom condition batching (getShouldExecute)\n * - Manual processing controls\n * - Public mutable options\n * - Callback support for monitoring batch execution and state changes\n *\n * Features NOT included (compared to core Batcher):\n * - No TanStack Store state management\n * - No devtools integration\n * - No complex state tracking (execution counts, etc.)\n * - No reactive state management\n *\n * @example\n * ```ts\n * // Basic batching\n * const batcher = new LiteBatcher<number>(\n *   (items) => console.log('Processing batch:', items),\n *   {\n *     maxSize: 5,\n *     wait: 2000,\n *     onExecute: (batch, batcher) => {\n *       console.log('Batch executed with', batch.length, 'items');\n *     },\n *     onItemsChange: (batcher) => {\n *       console.log('Batch size changed to:', batcher.size);\n *     }\n *   }\n * );\n *\n * batcher.addItem(1);\n * batcher.addItem(2);\n * // After 2 seconds or when 5 items are added, whichever comes first,\n * // the batch will be processed\n * ```\n *\n * @example\n * ```ts\n * // Custom condition batching\n * const batcher = new LiteBatcher<Task>(\n *   (items) => processTasks(items),\n *   {\n *     getShouldExecute: (items) => items.some(task => task.urgent),\n *     maxSize: 10,\n *   }\n * );\n *\n * batcher.addItem({ name: 'normal', urgent: false });\n * batcher.addItem({ name: 'urgent', urgent: true }); // Triggers immediate processing\n * ```\n */\nexport class LiteBatcher<TValue> {\n  private items: Array<TValue> = []\n  private timeoutId: NodeJS.Timeout | null = null\n  private _isPending = false\n\n  constructor(\n    public fn: (items: Array<TValue>) => void,\n    public options: LiteBatcherOptions<TValue> = {},\n  ) {\n    // Set defaults\n    this.options.maxSize = this.options.maxSize ?? Infinity\n    this.options.started = this.options.started ?? true\n    this.options.wait = this.options.wait ?? Infinity\n    this.options.getShouldExecute =\n      this.options.getShouldExecute ?? (() => false)\n  }\n\n  /**\n   * Number of items currently in the batch\n   */\n  get size(): number {\n    return this.items.length\n  }\n\n  /**\n   * Whether the batch has no items to process (items array is empty)\n   */\n  get isEmpty(): boolean {\n    return this.items.length === 0\n  }\n\n  /**\n   * Whether the batcher is waiting for the timeout to trigger batch processing\n   */\n  get isPending(): boolean {\n    return this._isPending\n  }\n\n  private getWait(): number {\n    if (typeof this.options.wait === 'function') {\n      return this.options.wait(this)\n    }\n    return this.options.wait!\n  }\n\n  /**\n   * Adds an item to the batcher\n   * If the batch size is reached, timeout occurs, or getShouldExecute returns true, the batch will be processed\n   */\n  addItem = (item: TValue): void => {\n    this.items.push(item)\n    this._isPending = this.options.wait !== Infinity\n    this.options.onItemsChange?.(this)\n\n    const shouldProcess =\n      this.items.length >= this.options.maxSize! ||\n      this.options.getShouldExecute!(this.items, this)\n\n    if (shouldProcess) {\n      this.execute()\n    } else if (this.options.wait !== Infinity) {\n      this.clearTimeout() // clear any pending timeout to replace it with a new one\n      this.timeoutId = setTimeout(() => this.execute(), this.getWait())\n    }\n  }\n\n  /**\n   * Processes the current batch of items.\n   * This method will automatically be triggered if the batcher is running and any of these conditions are met:\n   * - The number of items reaches maxSize\n   * - The wait duration has elapsed\n   * - The getShouldExecute function returns true upon adding an item\n   *\n   * You can also call this method manually to process the current batch at any time.\n   */\n  private execute = (): void => {\n    if (this.items.length === 0) {\n      return\n    }\n\n    const batch = this.peekAllItems() // copy of the items to be processed (to prevent race conditions)\n    this.clear() // Clear items before processing to prevent race conditions\n\n    this.fn(batch) // EXECUTE\n    this.options.onExecute?.(batch, this)\n  }\n\n  /**\n   * Processes the current batch of items immediately\n   */\n  flush = (): void => {\n    this.clearTimeout() // clear any pending timeout\n    this.execute() // execute immediately\n  }\n\n  /**\n   * Returns a copy of all items in the batcher\n   */\n  peekAllItems = (): Array<TValue> => {\n    return [...this.items]\n  }\n\n  private clearTimeout = (): void => {\n    if (this.timeoutId) {\n      clearTimeout(this.timeoutId)\n      this.timeoutId = null\n    }\n  }\n\n  /**\n   * Removes all items from the batcher\n   */\n  clear = (): void => {\n    const hadItems = this.items.length > 0\n    this.items = []\n    this._isPending = false\n    if (hadItems) {\n      this.options.onItemsChange?.(this)\n    }\n  }\n\n  /**\n   * Cancels any pending execution that was scheduled.\n   * Does NOT clear out the items.\n   */\n  cancel = (): void => {\n    this.clearTimeout()\n    this._isPending = false\n  }\n}\n\n/**\n * Creates a batcher that processes items in batches.\n *\n * This is an alternative to the batch function in the core @tanstack/pacer package, but is more\n * suitable for libraries and npm packages that need minimal overhead. Unlike the core version,\n * this function creates a batcher with no external dependencies, devtools integration, or reactive state.\n *\n * @example\n * ```ts\n * const batchItems = liteBatch<number>(\n *   (items) => console.log('Processing:', items),\n *   {\n *     maxSize: 3,\n *   }\n * );\n *\n * batchItems(1);\n * batchItems(2);\n * batchItems(3); // Triggers batch processing\n * ```\n */\nexport function liteBatch<TValue>(\n  fn: (items: Array<TValue>) => void,\n  options: LiteBatcherOptions<TValue> = {},\n): (item: TValue) => void {\n  const batcher = new LiteBatcher<TValue>(fn, options)\n  return batcher.addItem\n}\n"],"names":[],"mappings":";;AA4GO,MAAM,YAAoB;AAAA,EAK/B,YACS,IACA,UAAsC,IAC7C;AAFO,SAAA,KAAA;AACA,SAAA,UAAA;AANT,SAAQ,QAAuB,CAAA;AAC/B,SAAQ,YAAmC;AAC3C,SAAQ,aAAa;AA8CrB,SAAA,UAAU,CAAC,SAAuB;AAChC,WAAK,MAAM,KAAK,IAAI;AACpB,WAAK,aAAa,KAAK,QAAQ,SAAS;AACxC,WAAK,QAAQ,gBAAgB,IAAI;AAEjC,YAAM,gBACJ,KAAK,MAAM,UAAU,KAAK,QAAQ,WAClC,KAAK,QAAQ,iBAAkB,KAAK,OAAO,IAAI;AAEjD,UAAI,eAAe;AACjB,aAAK,QAAA;AAAA,MACP,WAAW,KAAK,QAAQ,SAAS,UAAU;AACzC,aAAK,aAAA;AACL,aAAK,YAAY,WAAW,MAAM,KAAK,WAAW,KAAK,SAAS;AAAA,MAClE;AAAA,IACF;AAWA,SAAQ,UAAU,MAAY;AAC5B,UAAI,KAAK,MAAM,WAAW,GAAG;AAC3B;AAAA,MACF;AAEA,YAAM,QAAQ,KAAK,aAAA;AACnB,WAAK,MAAA;AAEL,WAAK,GAAG,KAAK;AACb,WAAK,QAAQ,YAAY,OAAO,IAAI;AAAA,IACtC;AAKA,SAAA,QAAQ,MAAY;AAClB,WAAK,aAAA;AACL,WAAK,QAAA;AAAA,IACP;AAKA,SAAA,eAAe,MAAqB;AAClC,aAAO,CAAC,GAAG,KAAK,KAAK;AAAA,IACvB;AAEA,SAAQ,eAAe,MAAY;AACjC,UAAI,KAAK,WAAW;AAClB,qBAAa,KAAK,SAAS;AAC3B,aAAK,YAAY;AAAA,MACnB;AAAA,IACF;AAKA,SAAA,QAAQ,MAAY;AAClB,YAAM,WAAW,KAAK,MAAM,SAAS;AACrC,WAAK,QAAQ,CAAA;AACb,WAAK,aAAa;AAClB,UAAI,UAAU;AACZ,aAAK,QAAQ,gBAAgB,IAAI;AAAA,MACnC;AAAA,IACF;AAMA,SAAA,SAAS,MAAY;AACnB,WAAK,aAAA;AACL,WAAK,aAAa;AAAA,IACpB;AAtHE,SAAK,QAAQ,UAAU,KAAK,QAAQ,WAAW;AAC/C,SAAK,QAAQ,UAAU,KAAK,QAAQ,WAAW;AAC/C,SAAK,QAAQ,OAAO,KAAK,QAAQ,QAAQ;AACzC,SAAK,QAAQ,mBACX,KAAK,QAAQ,qBAAqB,MAAM;AAAA,EAC5C;AAAA;AAAA;AAAA;AAAA,EAKA,IAAI,OAAe;AACjB,WAAO,KAAK,MAAM;AAAA,EACpB;AAAA;AAAA;AAAA;AAAA,EAKA,IAAI,UAAmB;AACrB,WAAO,KAAK,MAAM,WAAW;AAAA,EAC/B;AAAA;AAAA;AAAA;AAAA,EAKA,IAAI,YAAqB;AACvB,WAAO,KAAK;AAAA,EACd;AAAA,EAEQ,UAAkB;AACxB,QAAI,OAAO,KAAK,QAAQ,SAAS,YAAY;AAC3C,aAAO,KAAK,QAAQ,KAAK,IAAI;AAAA,IAC/B;AACA,WAAO,KAAK,QAAQ;AAAA,EACtB;AAsFF;AAuBO,SAAS,UACd,IACA,UAAsC,IACd;AACxB,QAAM,UAAU,IAAI,YAAoB,IAAI,OAAO;AACnD,SAAO,QAAQ;AACjB;;;"}